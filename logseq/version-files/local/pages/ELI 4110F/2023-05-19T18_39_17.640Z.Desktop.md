- # Course Overview
	- Instructor: Dr. Solomon Asantey, P.Eng.
	  collapsed:: true
		- sasantey@uwo.ca
	- Course topics  
	  collapsed:: true
		- | **CATEGORY** | **TOPICS** |
		  | ---- | ---- | ---- |
		  | **Foundations                          ** | **Professionalism, History, Ethical Principles, The Law - Regulation and Enforcement** |
		  |  | *Module 1*: Professionalism and Engineering; Principles of ethics, character and decision making. |
		  |  | *Module 2*: The Canadian Legal System and Environmental Law; The Professional Engineers Act and the Code of Ethics; Lifelong Learning. |
		  |  | *Module 3*: Licensing and Discipline; Professional and ethical issues in consulting; Enforcement. |
		  | **Applications                         ** | **Law, Ethics and Equity Issues in the Workplace, the Environment and Emerging Technologies** |
		  |  | *Module 4*: Tort law principles; business and the engineerâ€™s liability; product safety; workplace safety; liability cases and intellectual property. |
		  |  | *Module 5*: Contract law principles; contract discharge, interpretation, and remedies. |
		  |  | *Module 6*: Ethics and conflicts in the workplace. |
		  |  | *Module 7*: Ethics of emerging technologies: transparency, safety, security, privacy. |
		  |  | *Module 8*: Sustainable development, social and economic justice. |
		  |  | *Module 9*: Environmental ethics; climate change. |
		  |  | *Module 10*: Equity, diversity & inclusion in hiring and in the workplace. |
	- Textbook(s)  
	  collapsed:: true
		- Andrews, Shaw and McPhee: Canadian Professional Engineering and Geoscience - Practice and Ethics, 6th edition. Toronto: Nelson, 2019
		- Marston: Law for Professional Engineers, 5th edition. Toronto: McGraw-Hill Education, 2019.
	- #[[Important course dates]]
	  collapsed:: true
		- Wednesday, May 24: Lifelong Learning Plan (5%) submission deadline.
		- Friday, June 2: Code of Ethics Research Paper (20%) submission deadline.
		- Friday, June 9: Online Multiple-choice linear Test (10%) covering Modules 1-5.
		- Tuesday, June 13: In-class Sustainable Development Quiz (5%) on OWL Quizzes.
		- Thursday, June 22: SUMMATIVE (25%) submission deadline (Introduced in Module 1, Opens in Module 7).
	- #[[Grading scheme]]
	  collapsed:: true
		- Formative, Individual Lifelong Learning Plan:        5%
		- Code of Ethics Research Paper, Individual:          20%
		- Team Presentation/Debate:                                      15%
		- Individual Contribution:                                             20%
		- Mid Term Test, Individual:                                         10%
		- Sustainable Development Quiz:                                 5%
		- Summative, Individual:                                              25%
# #[[Course Tasks]]
	- TODO Review 72 & 77 line by line (review some slides too)
	  SCHEDULED: <2023-05-18 Thu>
	- DONE Paraphrasing exercise
	  SCHEDULED: <2023-05-18 Thu>
	- DONE Leadership Development Plan initial
	  SCHEDULED: <2023-05-17 Wed>
	- TODO Leadership Development Plan draft
	  DEADLINE: <2023-05-23 Tue 18:30>
	  SCHEDULED: <2023-05-19 Fri>
	- TODO Leadership Development Plan final
	  SCHEDULED: <2023-05-23 Tue>
	  DEADLINE: <2023-05-24 Wed>
	- TODO Notes on first two lecs
	  SCHEDULED: <2023-05-21 Sun>
	- DONE Review syllabus and add above
	  SCHEDULED: <2023-05-12 Fri>
	- DONE Read over project info
	  SCHEDULED: <2023-05-13 Sat>
	- DONE Module 1 review
	  SCHEDULED: <2023-05-15 Mon>
	- DONE Module 2 review
	  SCHEDULED: <2023-05-16 Tue>
- # #[[Course Notes]]
	- Self-driving car dilemmas reveal that moral choices are not universal
		- **I. Key Ideas**
		- The development of autonomous vehicles has brought with it a host of ethical considerations. A survey called the Moral Machine, which was conducted to understand global moral decisions that guide a driver's actions, found that these principles can vary significantly by country. The study represents the largest survey of machine ethics to date and involved 2.3 million respondents worldwide.
		- Key findings from the survey indicate that cultural nuances greatly impact the moral decisions made in a driving scenario. These factors include prosperity levels, institutional strength, and cultural traditions. Such results suggest the impossibility of establishing a universally accepted moral code for autonomous vehicles. In addition, the study highlights that the ethical dilemmas posed by self-driving cars are re-energizing debates about universal versus culture-specific ethics.
		- **II. In-Depth Analysis**
		- The Moral Machine survey posed 13 scenarios in which a fatality was inevitable, and respondents had to choose who to spare. Variables included age, wealth status, and the number of people involved. It was observed that while some moral preferences were fairly universal (such as prioritizing human lives over pets), many differed based on cultural or economic context. For instance, respondents from countries with strong government institutions were more likely to choose hitting a pedestrian crossing the road illegally. On the other hand, those from nations with high economic inequality often chose to spare the wealthier individual in hypothetical scenarios.
		- The study found a correlation between a country's social and economic factors and the average opinions of its residents. This is a significant finding, given that it underscores the need for a culturally sensitive approach when programming the ethical decision-making process in autonomous vehicles.
		- **III. Discussion Points and Further Expansion/Explanation**
		- *How much should we try???*
		  collapsed:: true
			- Ethics and moral considerations are crucial to the development and deployment of autonomous vehicles. In fact, these factors are important in the development of any technology that interacts with or impacts human lives. The Moral Machine survey, in its effort to map global variations in ethics for autonomous vehicles, has unearthed cultural nuances that are difficult to incorporate into a universal code. This dilemma brings us to the question of how much weight or thought should be given to defining the morality of autonomous vehicles.
			- **Over-defining vs. Generalizing Scenarios**
			- The debate between over-defining scenarios and keeping them general presents a classic conundrum. On one hand, over-defining scenarios allows us to ensure that an autonomous vehicle will act in a predictable and desirable way in a wide array of specific situations. This can provide a sense of comfort and control, as we can anticipate how the vehicle will respond in nearly any circumstance.
			- However, the risk of over-defining scenarios is that it can lead to an overly complex and potentially unmanageable system. It's practically impossible to anticipate and define responses to every possible scenario a self-driving car could encounter. There's also the risk of creating a system that is too rigid to respond effectively to unanticipated or novel situations.
			- On the other hand, keeping scenarios general allows for more flexibility. A self-driving car programmed with general ethical principles can interpret and react to a wide array of situations, even those that its programmers did not specifically anticipate. This approach is more adaptive and potentially more robust in the face of the unexpected.
			- However, general scenarios also introduce ambiguity and unpredictability. If the ethical guidelines are too vague, different cars might interpret the same situation in different ways, leading to inconsistent behavior. This can lead to user mistrust and public discomfort, as people can't reliably predict how the vehicles will behave.
			- **Finding a Balance**
			- In essence, the challenge lies in striking a balance between the two extremes. It's important to define enough scenarios to ensure that autonomous vehicles act in ways that are predictable and consistent with our moral intuitions, but not so many that the system becomes overly complex and rigid. At the same time, the general principles guiding the vehicles' behavior need to be clear enough to ensure consistent behavior, but flexible enough to adapt to a wide array of situations.
			- The debate also highlights the need for public dialogue and regulatory oversight. Ethical decisions about how autonomous vehicles should behave in morally charged situations shouldn't be made solely by car manufacturers or tech companies. They should involve input from the public and be guided by regulations that reflect societal norms and values.
			- In conclusion, while the process of defining the moral code for autonomous vehicles is complex and fraught with challenges, it is a necessary step towards ensuring the safe and ethical integration of this technology into society.
		- *Ethics and Control*
		  collapsed:: true
			- Control and ethics are indeed deeply intertwined concepts, especially in the context of creating and managing technology that directly interacts with or affects human lives, such as autonomous vehicles.
			- **Control**
			- Control, in this context, refers to our ability to influence or direct the behavior of technology. Humans have an inherent desire for control over our environment, including the devices and systems we create. This desire is rooted in our survival instinct and has been a key driver of our technological progress.
			- In the case of autonomous vehicles, control refers to the ability to define and direct the behavior of these vehicles. This includes the ability to determine how they should react in various scenarios, particularly those involving potential harm to humans.
			- **Ethics**
			- Ethics, on the other hand, refers to the moral principles that guide our behavior or the conducting of an activity. When applied to technology, ethics helps us determine what behavior is acceptable or desirable for a device or system.
			- In the case of autonomous vehicles, ethics guides decisions about how these vehicles should behave in situations that involve potential harm to humans. For example, should an autonomous vehicle prioritize the safety of its passengers over pedestrians? Should it prioritize the lives of multiple people over a single person? These are ethical questions that require careful consideration.
			- **Link Between Control and Ethics**
			- The link between control and ethics is apparent in the process of defining the behavior of autonomous vehicles. We want to control the behavior of these vehicles to ensure that they act in ways that are consistent with our ethical values.
			- For instance, we might decide that it's ethically right for an autonomous vehicle to prioritize the lives of many people over the life of a single person. Once we've made that ethical decision, we can exercise control by programming the vehicle to behave in accordance with this principle.
			- However, this link also presents challenges. One of the biggest is the fact that ethics are not universal. What is considered ethical can vary greatly between different cultures, societies, and individuals. This makes it difficult to create a universal set of ethical guidelines for autonomous vehicles that is acceptable to everyone.
			- Another challenge is the potential loss of control that comes with increasingly autonomous systems. As technology becomes more capable of making decisions and taking actions on its own, we risk losing our ability to control its behavior. This raises ethical questions about how much autonomy we should give to technology and what safeguards we need to put in place to prevent misuse or harm.
			- In conclusion, the link between control and ethics is a central aspect of the development and management of technologies like autonomous vehicles. It underscores the need for careful consideration of ethical principles, public dialogue, and regulatory oversight in the design and implementation of these technologies.
		- The findings of the Moral Machine survey have far-reaching implications in the field of autonomous vehicles and beyond. They underscore the complexity of programming ethical decision-making into machines, particularly when those machines will be used globally.
		- One key issue is the challenge of reconciling culturally specific ethical norms with the need for a standardized set of rules for self-driving cars. How should carmakers and regulatory bodies navigate these differences? Is a middle ground possible, or will self-driving cars have to be programmed differently for different markets?
		- There's also the question of how much weight these ethical considerations should carry in the development and deployment of autonomous vehicles. The debate centers around whether these scenarios are too rare or unrealistic to warrant significant attention or whether they represent crucial moral judgments that self-driving cars will have to make routinely.
		- Finally, the survey results may be a useful starting point for public discussions about the moral dilemmas posed by self-driving cars. Such conversations could help build public trust and acceptance of these vehicles, which will be crucial for their widespread adoption.
		- In conclusion, the Moral Machine survey is a significant step in understanding the complex ethical landscape surrounding self-driving cars. However, much work remains to be done in terms of translating these insights into practical guidelines for the development and regulation of autonomous vehicles.
		- **IV. Point Form**
		  collapsed:: true
			- **I. Key Ideas**
				- Autonomous vehicles raise complex ethical considerations.
				- The Moral Machine survey was conducted to understand global variations in moral choices for self-driving cars.
				- The survey involved 2.3 million respondents worldwide.
				- Findings suggest that moral principles guiding a driver's actions vary significantly by country.
				- There appears to be no universally accepted moral code for autonomous vehicles due to these cultural nuances.
			- **II. In-Depth Analysis**
				- The Moral Machine survey posed 13 scenarios involving inevitable fatalities, with respondents choosing who to spare.
				- Variables included age, wealth status, and the number of people involved.
				- Universal moral preferences included prioritizing human lives over pets.
				- However, choices varied based on cultural or economic context, such as institutional strength and economic equality.
				- The study found correlations between a country's social and economic factors and the average opinions of its residents.
			- **III. Discussion Points and Further Expansion/Explanation**
				- The findings underscore the complexity of programming ethical decision-making into machines for global use.
				- There is a challenge in reconciling culturally specific ethical norms with the need for standardized rules for self-driving cars.
				- The weight of these ethical considerations in the development and deployment of autonomous vehicles is a topic of debate.
				- The survey results could be useful for initiating public discussions about the moral dilemmas posed by self-driving cars.
				- The survey is a significant step in understanding the complex ethical landscape surrounding self-driving cars, but much work remains to be done.